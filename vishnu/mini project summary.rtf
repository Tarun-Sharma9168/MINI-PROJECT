{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Calibri;}{\f1\fnil Calibri;}}
{\*\generator Riched20 10.0.17763}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9 Requirement Engineering of Software Product Lines: Extracting Variability using NLP\par
Among the fundamental activities of software product line engineering (SPLE) there is the identification of the variability in different artifacts of the system, such as requirements, architecture and test cases . In particular, in the requirement engineering of software product lines (SPL), several researches have focused on exploiting natural language processing (NLP) techniques and tools to extract information related to features and variability from documents in natural language (NL) in general  and requirement documents in particular.\par
In previous works  we initiated a line of research to extract variability issues from the NL sentences in a requirement document using an existing NLP tool aimed at revealing ambiguity defects. The underlying intuition is that often ambiguity in requirements is due to the (conscious or subconscious) need to postpone choices for later decisions in the implementation of the system. Ambiguities normally cause inconsistencies between the expectation of the customer and the product developed, and possibly lead to undesirable reworks on the artifacts.\par
Specifically, we envisioned an approach to achieve automated support to variability elicitation by analysing the outcomes of automated ambiguity detection applied to some set of requirements by means of the QuARS (Quality Analyser for Requirements Specifications) tool , a well known tool for analyzing NL requirements in a systematic and automatic way. QuARS allows to perform an initial parsing of NL requirements for detecting potential linguistic defects that can determine interpretation problems.\par
  We initiated a validation of the approach with QuARS, in order to:\par
\f1\bullet  assess whether ambiguities in NL requirements can be\f0\lang1033  \f1\lang9 considered as potential variation points\f0\lang1033 .\f1\lang9\par
\bullet  assess to which extent the process of variability identification can be automated with an ambiguity detection tool\f0\lang1033  \f1\lang9 such as QuARS,\par
\bullet  refine the definition of a possible NLP tool for variability\f0\lang1033  \f1\lang9 detection\f0\lang1033 .\par
To this aim, our research questions (RQs) are the following:\par
RQ1 Is automated ambiguity detection in NL requirement documents a proxy to detect variability?\par
RQ2 Which are the ambiguity indicators that are most relevant to detect variability, if any?\par
RQ3 The variability detection process can benefit from adding a new variability tailored dictionay to an existing NL requirements analysis tool?\par
Some initial answers to theses RQs are in [8], where we have shown that an ambiguity detection tool can be helpful to detect variability, stimulating a more systematic and deep\par
experience. Hence, we  systematically address the RQs using three requirement documents of medium to large size, that are publicly available and refer to different domains and systems to be built, and assess the results by using well known statistical measures. Exploiting the experience made in past work, we also define a new dictionary to be added to QuARS, designed to provide an indicator for variability, and we extend the experiments and measures to this new indicator as well.\par
\ul Relevance to RE\par
\ulnone In the field of product line engineering, the use of NLP techniques to identify variation points in single requirements documents is justified by the following observations:\par
(1) NL is intrinsically ambiguous, and this is seen often as a possible source of problems in the later interpretation of requirements. However, ambiguity or underspecification at requirements level can in some cases give an indication of possible variability, either in design choices, in implementation choices or configuration.\par
(2) In this paper we presents an extensive, and empirically grounded, experimentation to validate the approach presented in our previous works  which had an exploratory nature and were mainly oriented to scope the problem.\par
\ul QUARS\par
\ulnone QuARS was introduced as an automatic analyzer of requirement documents . QuARS performs an initial parsing of NL requirements for automatic detection of potential linguistic defects that can determine ambiguity problems impacting the following development stages. QuARS executes a linguistic analysis of a requirements document in plain text format and points out the sentences that are defective according to the quality model described in . The defect identification process is split in two parts: \par
(i) the \ldblquote lexical analysis\rdblquote  capturing optionality, subjectivity, vagueness, multiplicity and weakness defects, by identifying candidate defective terms that are identified into a corresponding set of dictionaries; and\par
(ii) the \ldblquote syntactical analysis\rdblquote  capturing implicity and underspecification defects. In the same way, detected defects may however be false defects \f1\endash  i.e., false positives.\par
\ul RESEARCH DESIGN\par
\ulnone Requirement Document\f0 s\par
We base our analysis on three requirements documents that are very different from each other in terms of domain,characteristics of the systems, and background and experience  of their authors.\par
1) European Integrated Railway Radio Enhanced Network (Eirene): The \ldblquote Eirene\rdblquote  document has been issued by the GSM-R Functional Group and it specifies the functional requirements for a digital radio standard for the European railways. The document includes 475 requirements.\par
2) Library: The second document, \ldblquote Library\rdblquote , was prepared by the Galecia Group, a company specialised in libraries and organizations supporting libraries. It describes the functional and nonfunctional requirements for the System Administration Module of the Integrated Library System of a urban library system. It includes 94 requirements.\par
3) Blit: \ldblquote Blit\rdblquote , is a draft of the functional specification of the requirements of a business project management tool, required by a company for re-writing its core Laboratory Information System to improve the performance. The authors of the document, which includes 55 requirements, are anonymous.\par
Data Collection and Analysis\par
 To elicit the potential variability hidden in a requirement document, we perform an assessment of the output of the tool, for each ambiguity indicator, aimed at classifying the defective sentences and distinguish among: false positives, variability points, and actual ambiguities.\par
More specifically, the data collection procedure, for each document, consists of the following steps:\par
Automatic Detection: The document is given as input to QuARS in textual format, and QuARS produces a set of sentences that are considered ambiguous, together with the term or expression that is the source of the ambiguity;\par
Review: The output of QuARS is reviewed by the 3rd author on the one side, and, independently, by the 4th one. Each defect identified by QuARS has been identified as: false positives, variability, or ambiguity;\par
Assessment: The classification is reviewed by the 3rd and 4th authors, who discussed the discrepancies emerged in the judgment and looked for an agreement. The classification derived in this phase is the one used for data analysis.\par
Review and assessment phases, that highlight variation points, are based on the criteria introduced in our previous paper : ambiguity in requirements may be due to the need to enlighten possible variation points in an early phase of software and system development and to postpone choices for later decisions in the implementation of the system.\par
With under-specification and vagueness the criterion to identify a variability is the existence of more than one possible instance of the defective term. With multiplicity the reviewer can mark as false positives all the requirements where the term \ldblquote or\rdblquote , \ldblquote and/or\rdblquote  and similar relate two sentences or two adjectives, and use their judgment in the cases where they relate nouns. The cases of weakness and optionality are treated similarly, since the nature of these defects is inherently associated to variation points, especially when they appear in functional requirements.\par
The data analysis procedure, for each document, consists of the following steps:\par
Agreement: The annotations of the two independent reviewers are compared by means of the Fleiss Kappa, to have an indication of judgments\rquote  discrepancies.\par
Quantitative Analysis: The number of defects found by the tool (fnd), false positives (fp), variability indicators (var), and the actual ambiguities (amb) is computed for each indicator, based on the data collected in the Assessment step.\par
Precision general formula is:\par
preci =tpi/fndi\par
where fndi = tpi+f pi is the number of all the terms found by QuARS, i.e. the sum of true positive and false positive (resp.) classifications for indicator i. To have a full picture and to compare the results, we calculate the precision of QuARS in detecting, for each indicator, both ambiguities and variabilities:\par
p ambi =ambi/fndi\par
p vari =vari/fndi\par
Aggregate values are also computed for these indicators.\par
Qualitative Analysis: For each indicator showing a substantially higher precision than others, we look whether some terms in the corresponding vocabulary can be considered variability-related terms. This analysis aims to provide a more refined answer to RQ2. Furthermore, we inspect the requirements to discover additional terms to be used, provide an answer to RQ3, and further iterate the data analysis process.\par
\ul RESULTS AND OBSERVATIONS\par
\ulnone The agreement between annotators on the whole output of QuARS resulted in 0.455, indicating a moderate agreement.For each indicator, we report the number of defects found by the tool (fnd), the number of false positives (fp), the actual ambiguities (amb), and the variability indicators (var), as classified by manual inspection. The last two rows indicate the precision of QuARS in identifying ambiguities (p amb) and variability points (p var), respectively.\par
We analyse in the following the single indicators. With multiplicity, variability is actually an option and true positives are equally distributed between \ldblquote or\rdblquote  and \ldblquote and/or\rdblquote .\par
An example is: The setting up and closing down of a multi-driver call shall be simplified using automation or guidance through the steps required.\par
We did not find any optionality defect in any of the considered documents, and only 1 for subjectivity: at least for these case studies these indicators are definitely not relevant.\par
Vagueness is due to the presence of undetermined adjectives and adverbs and can mask a variability, even though in few cases, like in:\par
Various types of call restriction may be employed by the railways as an additional security measure.\par
We classified as variability sources some requirements including the terms possible and capable. However, the true source of variablity was due to term where: Where fax functionality is provided, it shall be possible to interrupt the fax to make or receive a high priority voice or data call. We have exploited this observation to add to the Tailored Dictionary terms as where, when, if, whether. A further ambiguity indicator of QuARS is weakness. A sentence with verbs may or can, etc. is considered weak, e.g.: A driver may be provided with a handheld portable to allow communications whilst the driver is outside the train.\par
For the implicity indicator, a sentence is considered defective if its subject or complements are implicit, being expressed by demonstrative adjectives (this, these, that, those) or pronouns (it, they, etc.) instead of by a noun. In the considered documents, implicity is in most cases resolved when reading the sentence, and, in any case, it is never an indication of possible variability. Also in the case of under-specification, most defective sentences are false positives, and almost no variability is hidden behind.\par
Finally, the defects revealed using the Tailored Dictionary show a performance in line with that related to multiplicity and weakness indicators. However, we observed that, in most cases, variability was hidden in requirements including pairs of terms of the kind when. . . possible, if. . . implemented, etc, when occurring in the same sentence, as in: If the text message facility is implemented, it shall not interfere with the ability of users to make or receive high priority voice or data calls. while they were most probably false positives when occurring in two different sentences of the same requirement, as in: When the call is connected to the controller, an audible and visual indication is to be provided to the driver.\par
 \ul THREATS TO VALIDITY\par
\ulnone Construct Validity An objective and widely used metric, i.e., precision, was used to assess the appropriateness of QuARS in identifying variabilities. Since the data used to calculate the precision are based on subjective evaluations, to mitigate subjectivity threats, we assessed the agreement among annotators by means of the Fleiss Kappa, which indicated a moderate agreement.Furthermore, an Assessment followed the Review step to define the final dataset used for analysis. It is worth noting that we did not use the recall measure to assess our results, since we annotated the requirements for variability after the application of QuARS.\par
Therefore, some variability indicators may exist in the original requirements that are not considered in our analysis.\par
Internal Validity :The main threat to the internal validity of the study is the involvement of the authors of this work in the Review and Assessment phase of the data collection procedure. We agree that the researcher bias might have played a role in these phases. However, this is mitigated by the evaluation of agreement. Furthermore, other researchers can replicate our approach using the publicly available1 QuARS tool, and using the documents employed in our evaluation.\par
External Validity: Our results are limited to three requirements documents. However, the documents are representative of different domains, and we have observed that several variability-related terms are common among the documents. \par
 \ul CONCLUSION\par
\ulnone  In this paper, we present the empirical evaluation of the idea, performed on three documents from industry of 624 requirements in total. The evaluation shows that some ambiguous terms, such as \ldblquote and/or\rdblquote  \ldblquote or\rdblquote , and weak terms such as \ldblquote may\rdblquote  or \ldblquote could\rdblquote  are more likely to indicate variability rather than ambiguity. Instead, typically vague terms, such as \ldblquote useful\rdblquote , \ldblquote significant\rdblquote , etc. are more likely to indicate ambiguity. We also show that rule-based lexical approaches such as the one mainly used by QuARS lead to a relevant number of false positive cases. This indicates that, although other authors recommend the usage of lexical approaches for RE activities to maximise recall , there is also a need for more advanced syntactic/semantic solutions to increase precision, and make NLP for RE approaches applicable in practice.. This is particularly true for variability detection:indeed, while ambiguities in safety-critical requirements may lead to potential system failures, non-identified variabilities may not have such severe consequences, and loosing some recall in favour of precision would speed-up the system analysis process. \par
}
 